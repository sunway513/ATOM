

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ATOM Scheduling &amp; KV Cache Guide &mdash; ATOM 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=9edc463e" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=01f34227"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="ATOM Distributed Inference Guide" href="distributed_guide.html" />
    <link rel="prev" title="ATOM Model Operations Guide" href="model_ops_guide.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #C00000" >

          
          
          <a href="index.html" class="icon icon-home">
            ATOM
              <img src="_static/atom_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#installation-methods">Installation Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="installation.html#from-source">From Source</a></li>
<li class="toctree-l3"><a class="reference internal" href="installation.html#docker-installation">Docker Installation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#environment-variables">Environment Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#verification">Verification</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#serving-a-model">Serving a Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#batch-inference">Batch Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#distributed-serving">Distributed Serving</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#api-server">API Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#performance-tips">Performance Tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#next-steps">Next Steps</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guides</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="architecture_guide.html">ATOM Architecture Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="architecture_guide.html#system-overview">1. System Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture_guide.html#component-architecture">2. Component Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture_guide.html#request-lifecycle">3. Request Lifecycle</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture_guide.html#forward-context-pattern">4. Forward Context Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture_guide.html#multi-process-architecture">5. Multi-Process Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture_guide.html#sequence-lifecycle">6. Sequence Lifecycle</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture_guide.html#source-files">Source Files</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="configuration_guide.html">ATOM Configuration Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#master-configuration-config">1. Master Configuration (<code class="docutils literal notranslate"><span class="pre">Config</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#compilation-configuration-compilationconfig">2. Compilation Configuration (<code class="docutils literal notranslate"><span class="pre">CompilationConfig</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="configuration_guide.html#compilation-levels-compilationlevel">2.1 Compilation Levels (<code class="docutils literal notranslate"><span class="pre">CompilationLevel</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="configuration_guide.html#compilationconfig-fields">2.2 <code class="docutils literal notranslate"><span class="pre">CompilationConfig</span></code> Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="configuration_guide.html#cuda-graph-mode-cudagraphmode">2.3 CUDA Graph Mode (<code class="docutils literal notranslate"><span class="pre">CUDAGraphMode</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#quantization-configuration-quantizationconfig">3. Quantization Configuration (<code class="docutils literal notranslate"><span class="pre">QuantizationConfig</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="configuration_guide.html#quantizationconfig-fields">3.1 <code class="docutils literal notranslate"><span class="pre">QuantizationConfig</span></code> Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="configuration_guide.html#quanttype-values-from-aiter">3.2 <code class="docutils literal notranslate"><span class="pre">QuantType</span></code> Values (from AITER)</a></li>
<li class="toctree-l3"><a class="reference internal" href="configuration_guide.html#supported-quantization-dtypes">3.3 Supported Quantization Dtypes</a></li>
<li class="toctree-l3"><a class="reference internal" href="configuration_guide.html#auto-detection-from-huggingface-get-quant-config">3.4 Auto-Detection from HuggingFace (<code class="docutils literal notranslate"><span class="pre">get_quant_config</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#parallel-configuration-parallelconfig">4. Parallel Configuration (<code class="docutils literal notranslate"><span class="pre">ParallelConfig</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#speculative-decoding-configuration-speculativeconfig">5. Speculative Decoding Configuration (<code class="docutils literal notranslate"><span class="pre">SpeculativeConfig</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#sampling-parameters-samplingparams">6. Sampling Parameters (<code class="docutils literal notranslate"><span class="pre">SamplingParams</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#cli-arguments-engineargs">7. CLI Arguments (<code class="docutils literal notranslate"><span class="pre">EngineArgs</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#environment-variables">8. Environment Variables</a><ul>
<li class="toctree-l3"><a class="reference internal" href="configuration_guide.html#variables-registered-in-atom-utils-envs-py">8.1 Variables Registered in <code class="docutils literal notranslate"><span class="pre">atom/utils/envs.py</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="configuration_guide.html#additional-environment-variables-used-outside-envs-py">8.2 Additional Environment Variables (Used Outside <code class="docutils literal notranslate"><span class="pre">envs.py</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#decision-tree-choosing-a-compilation-level">9. Decision Tree – Choosing a Compilation Level</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration_guide.html#source-files">Source Files</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_support_guide.html">ATOM Model Support Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_support_guide.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_support_guide.html#supported-model-architectures">1. Supported Model Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_support_guide.html#model-architecture-details">2. Model Architecture Details</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#qwen3-qwen3forcausallm">Qwen3 (<code class="docutils literal notranslate"><span class="pre">Qwen3ForCausalLM</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#qwen3-moe-qwen3moeforcausallm">Qwen3-MoE (<code class="docutils literal notranslate"><span class="pre">Qwen3MoeForCausalLM</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#llama-llamaforcausallm">Llama (<code class="docutils literal notranslate"><span class="pre">LlamaForCausalLM</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#mixtral-mixtralforcausallm">Mixtral (<code class="docutils literal notranslate"><span class="pre">MixtralForCausalLM</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#deepseek-v2-v3-deepseekv2forcausallm">DeepSeek V2/V3 (<code class="docutils literal notranslate"><span class="pre">DeepseekV2ForCausalLM</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#deepseek-mtp-deepseekmtp">DeepSeek MTP (<code class="docutils literal notranslate"><span class="pre">DeepSeekMTP</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#gpt-oss-gptossforcausallm">GPT-OSS (<code class="docutils literal notranslate"><span class="pre">GptOssForCausalLM</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#glm4-moe-glm4moeforcausallm">GLM4-MoE (<code class="docutils literal notranslate"><span class="pre">Glm4MoeForCausalLM</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_support_guide.html#weight-loading">3. Weight Loading</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#function-signature">Function Signature</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#loading-flow">Loading Flow</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#layers-beyond-num-hidden-layers">Layers Beyond <code class="docutils literal notranslate"><span class="pre">num_hidden_layers</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_support_guide.html#adding-a-new-model">4. Adding a New Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#step-1-create-the-model-file">Step 1: Create the Model File</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#step-2-implement-layer-classes">Step 2: Implement Layer Classes</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#step-3-implement-the-model-and-causallm-classes">Step 3: Implement the Model and CausalLM Classes</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#step-4-register-the-model">Step 4: Register the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#step-5-handle-weight-loading">Step 5: Handle Weight Loading</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_support_guide.html#model-specific-optimizations">5. Model-Specific Optimizations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#llama-fused-rmsnorm-quant-and-silu-mul-quant">Llama: Fused RMSNorm+Quant and SiLU+Mul+Quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#deepseek-v2-v3-mla-fused-input-norm-qk-norm-fusion">DeepSeek V2/V3: MLA + Fused Input Norm + QK Norm Fusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#qwen3-moe-qk-norm-rope-cache-quant-fusion">Qwen3-MoE: QK Norm + RoPE + Cache + Quant Fusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_support_guide.html#mtp-deepseek-multi-token-prediction">MTP: DeepSeek Multi-Token Prediction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_support_guide.html#source-files">Source Files</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_ops_guide.html">ATOM Model Operations Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#aiter-integration-overview">1. AITER Integration Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#aiter-kernel-mapping-table">AITER Kernel Mapping Table</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#linear-operations">2. Linear Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#class-hierarchy">2.1 Class Hierarchy</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#quantization-dispatch">2.2 Quantization Dispatch</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#tensor-parallel-sharding">2.3 Tensor Parallel Sharding</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#weight-processing">2.4 Weight Processing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#attention-operations">3. Attention Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#base-attention-base-attention-py">3.1 Base: <code class="docutils literal notranslate"><span class="pre">Attention</span></code> (<code class="docutils literal notranslate"><span class="pre">base_attention.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#multi-head-attention-attention-mha-py">3.2 Multi-Head Attention (<code class="docutils literal notranslate"><span class="pre">attention_mha.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#multi-head-latent-attention-attention-mla-py">3.3 Multi-head Latent Attention (<code class="docutils literal notranslate"><span class="pre">attention_mla.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#backend-abstraction-attentions-backends-py">3.4 Backend Abstraction (<code class="docutils literal notranslate"><span class="pre">attentions/backends.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#kv-cache-operations">3.5 KV Cache Operations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#mixture-of-experts-moe">4. Mixture of Experts (MoE)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#fusedmoe-class-moe-py">4.1 <code class="docutils literal notranslate"><span class="pre">FusedMoE</span></code> Class (<code class="docutils literal notranslate"><span class="pre">moe.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#quantization-methods">4.2 Quantization Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#topk-routing-topk-py">4.3 TopK Routing (<code class="docutils literal notranslate"><span class="pre">topK.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#fusedmoeparallelconfig">4.4 <code class="docutils literal notranslate"><span class="pre">FusedMoEParallelConfig</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#mori-integration-fused-moe-mori-prepare-finalize-py">4.5 MORI Integration (<code class="docutils literal notranslate"><span class="pre">fused_moe/mori_prepare_finalize.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#moe-quantization-config-fused-moe-config-py">4.6 MoE Quantization Config (<code class="docutils literal notranslate"><span class="pre">fused_moe/config.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#triton-moe-fallback-fused-moe-triton-py">4.7 Triton MoE Fallback (<code class="docutils literal notranslate"><span class="pre">fused_moe_triton.py</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#normalization">5. Normalization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#rmsnorm-layernorm-py">5.1 <code class="docutils literal notranslate"><span class="pre">RMSNorm</span></code> (<code class="docutils literal notranslate"><span class="pre">layernorm.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#layernorm-layernorm-py">5.2 <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> (<code class="docutils literal notranslate"><span class="pre">layernorm.py</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#activation-functions">6. Activation Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#siluandmul-activation-py">6.1 <code class="docutils literal notranslate"><span class="pre">SiluAndMul</span></code> (<code class="docutils literal notranslate"><span class="pre">activation.py</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#embedding-output-head">7. Embedding &amp; Output Head</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#vocabparallelembedding-embed-head-py">7.1 <code class="docutils literal notranslate"><span class="pre">VocabParallelEmbedding</span></code> (<code class="docutils literal notranslate"><span class="pre">embed_head.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#parallellmhead-embed-head-py">7.2 <code class="docutils literal notranslate"><span class="pre">ParallelLMHead</span></code> (<code class="docutils literal notranslate"><span class="pre">embed_head.py</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#rotary-position-embedding-rope">8. Rotary Position Embedding (RoPE)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#rotaryembedding-rotary-embedding-py">8.1 <code class="docutils literal notranslate"><span class="pre">RotaryEmbedding</span></code> (<code class="docutils literal notranslate"><span class="pre">rotary_embedding.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#get-rope-factory">8.2 <code class="docutils literal notranslate"><span class="pre">get_rope()</span></code> Factory</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#integration-in-attention">8.3 Integration in Attention</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#sampling">9. Sampling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#sampler-sampler-py">9.1 <code class="docutils literal notranslate"><span class="pre">Sampler</span></code> (<code class="docutils literal notranslate"><span class="pre">sampler.py</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#rejectionsampler-rejection-sampler-py">9.2 <code class="docutils literal notranslate"><span class="pre">RejectionSampler</span></code> (<code class="docutils literal notranslate"><span class="pre">rejection_sampler.py</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#fused-kernel-chains">10. Fused Kernel Chains</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_ops_guide.html#source-files">Source Files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#atom-model-ops"><code class="docutils literal notranslate"><span class="pre">atom/model_ops/</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#atom-model-ops-attentions"><code class="docutils literal notranslate"><span class="pre">atom/model_ops/attentions/</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#atom-model-ops-fused-moe"><code class="docutils literal notranslate"><span class="pre">atom/model_ops/fused_moe/</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="model_ops_guide.html#atom-utils"><code class="docutils literal notranslate"><span class="pre">atom/utils/</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ATOM Scheduling &amp; KV Cache Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#quick-reference">Quick Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scheduling-algorithm">1. Scheduling Algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-initialization">1.1 Scheduler Initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#schedule-flow">1.2 Schedule Flow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#delay-factor">1.3 Delay Factor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preemption">1.4 Preemption</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scheduledbatch-structure">2. ScheduledBatch Structure</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#constructor-signature">2.1 Constructor Signature</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fields">2.2 Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduledbatchoutput">2.3 ScheduledBatchOutput</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#block-manager">3. Block Manager</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#block-class">3.1 Block Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#blockmanager-initialization">3.2 BlockManager Initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#allocation-allocate">3.3 Allocation (<code class="docutils literal notranslate"><span class="pre">allocate</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deallocation-deallocate">3.4 Deallocation (<code class="docutils literal notranslate"><span class="pre">deallocate</span></code>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#can-allocate-and-can-append-checks">3.5 Can-Allocate and Can-Append Checks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#may-append-decode-extension">3.6 May-Append (Decode Extension)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#prefix-caching">4. Prefix Caching</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hash-function">4.1 Hash Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hash-chaining">4.2 Hash Chaining</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cache-lookup-during-allocation">4.3 Cache Lookup During Allocation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reference-counting">4.4 Reference Counting</a></li>
<li class="toctree-l3"><a class="reference internal" href="#enabling-prefix-caching">4.5 Enabling Prefix Caching</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#postprocessing">5. Postprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#signature">5.1 Signature</a></li>
<li class="toctree-l3"><a class="reference internal" href="#token-appending">5.2 Token Appending</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stop-condition-checking">5.3 Stop Condition Checking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stream-output">5.4 Stream Output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequence-cleanup">5.5 Sequence Cleanup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#placeholder-insertion">5.6 Placeholder Insertion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#speculative-decoding-integration">6. Speculative Decoding Integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-tracking">6.1 Scheduler Tracking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#draft-tokens-in-scheduling">6.2 Draft Tokens in Scheduling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#acceptance-statistics">6.3 Acceptance Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#draft-token-storage-on-sequences">6.4 Draft Token Storage on Sequences</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#sequence-management">7. Sequence Management</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#constructor">7.1 Constructor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#core-fields">7.2 Core Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="#timing-fields">7.3 Timing Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="#computed-properties">7.4 Computed Properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#num-tokens-setter">7.5 num_tokens Setter</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lifecycle">7.6 Lifecycle</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequencestatus-enum">7.7 SequenceStatus Enum</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequencetype-enum">7.8 SequenceType Enum</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#source-files">Source Files</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="distributed_guide.html">ATOM Distributed Inference Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="distributed_guide.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed_guide.html#tensor-parallelism-tp">1. Tensor Parallelism (TP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#weight-sharding">Weight Sharding</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#process-group-initialization">Process Group Initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#allreduce">AllReduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#configuration">Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distributed_guide.html#data-parallelism-dp">2. Data Parallelism (DP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#architecture">Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#dp-process-group-initialization">DP Process Group Initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#synchronized-busy-loop">Synchronized Busy Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#dummy-batch-execution">Dummy Batch Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#device-assignment">Device Assignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#dpmetadata">DPMetadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#coremanager-dp-orchestration">CoreManager (DP Orchestration)</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#id1">Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distributed_guide.html#expert-parallelism-ep">3. Expert Parallelism (EP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#fusedmoeparallelconfig">FusedMoEParallelConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#expert-distribution">Expert Distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#mori-communication">MORI Communication</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#id2">Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distributed_guide.html#environment-variables">4. Environment Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed_guide.html#multi-gpu-deployment-examples">5. Multi-GPU Deployment Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#deepseek-r1-on-8-gpus-tp8">DeepSeek-R1 on 8 GPUs (TP8)</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#qwen3-235b-a22b-on-8-gpus-tp8-ep">Qwen3-235B-A22B on 8 GPUs (TP8 + EP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#kimi-k2-thinking-on-4-gpus-tp4">Kimi-K2-Thinking on 4 GPUs (TP4)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distributed_guide.html#combined-parallelism-strategies">6. Combined Parallelism Strategies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#tp-only-dense-models">TP Only (Dense Models)</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#tp-ep-moe-models">TP + EP (MoE Models)</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#tp-dp-dense-throughput">TP + DP (Dense Throughput)</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#tp-dp-ep-moe-throughput">TP + DP + EP (MoE Throughput)</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed_guide.html#dp-attention-mode">DP Attention Mode</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distributed_guide.html#source-files">Source Files</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="compilation_cudagraph_guide.html">ATOM Compilation &amp; CUDA Graphs Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="compilation_cudagraph_guide.html#compilation-levels">1. Compilation Levels</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#level-0-no-compilation">Level 0 – NO_COMPILATION</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#level-1-dynamo-as-is">Level 1 – DYNAMO_AS_IS</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#level-2-dynamo-once">Level 2 – DYNAMO_ONCE</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#level-3-piecewise-production-default">Level 3 – PIECEWISE (Production Default)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compilation_cudagraph_guide.html#cuda-graph-modes">2. CUDA Graph Modes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#none-value-0">NONE (value: 0)</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#piecewise-value-1">PIECEWISE (value: 1)</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#full-value-2">FULL (value: 2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#full-decode-only-value-full-none">FULL_DECODE_ONLY (value: (FULL, NONE))</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#full-and-piecewise-value-full-piecewise">FULL_AND_PIECEWISE (value: (FULL, PIECEWISE))</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#helper-methods">Helper Methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compilation_cudagraph_guide.html#cuda-graph-capture">3. CUDA Graph Capture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#capture-flow">Capture Flow</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#graph-keying">Graph Keying</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#graph-pool-sharing">Graph Pool Sharing</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#default-capture-sizes">Default Capture Sizes</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#graph-replay-in-run-model">Graph Replay in run_model()</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compilation_cudagraph_guide.html#piecewise-compilation">4. Piecewise Compilation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#splitting-operations">Splitting Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#compilation-pipeline">Compilation Pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#cache-management">Cache Management</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compilation_cudagraph_guide.html#forward-context-stateless-dispatch">5. Forward Context &amp; Stateless Dispatch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#forwardcontext-fields">ForwardContext Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#lifecycle">Lifecycle</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#context-dataclass">Context Dataclass</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#integration-with-cuda-graphs">Integration with CUDA Graphs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compilation_cudagraph_guide.html#compiler-backend">6. Compiler Backend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#compilermanager">CompilerManager</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#compilerinterface">CompilerInterface</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#inductoradaptor">InductorAdaptor</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#inductorstandaloneadaptor">InductorStandaloneAdaptor</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#vllmbackend">VllmBackend</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#support-torch-compile-decorator">&#64;support_torch_compile Decorator</a></li>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#custom-op-registration">Custom Op Registration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compilation_cudagraph_guide.html#configuration-options">7. Configuration Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="compilation_cudagraph_guide.html#decision-tree">8. Decision Tree</a><ul>
<li class="toctree-l3"><a class="reference internal" href="compilation_cudagraph_guide.html#common-configurations">Common Configurations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="compilation_cudagraph_guide.html#source-files">Source Files</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="serving_benchmarking_guide.html">ATOM Serving &amp; Benchmarking Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#openai-compatible-server">1. OpenAI-Compatible Server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#endpoints">1.1 Endpoints</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#request-models">1.2 Request Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#response-models">1.3 Response Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#server-startup">1.4 Server Startup</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#example-curl">1.5 Example: curl</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#programmatic-api-llmengine">2. Programmatic API (LLMEngine)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#initialization">2.1 Initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#samplingparams">2.2 SamplingParams</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#core-methods">2.3 Core Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#synchronous-generation-example">2.4 Synchronous Generation Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#asynchronous-streaming-usage">2.5 Asynchronous / Streaming Usage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#simple-inference">3. Simple Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#usage">3.1 Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#what-it-does">3.2 What It Does</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#benchmarking">4. Benchmarking</a><ul>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#metrics">4.1 Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#key-cli-arguments">4.2 Key CLI Arguments</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#backend-request-functions">4.3 Backend Request Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#full-benchmark-example">4.4 Full Benchmark Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#profiling">5. Profiling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#configuration">5.1 Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#online-profiling-http">5.2 Online Profiling (HTTP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#programmatic-profiling">5.3 Programmatic Profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#offline-profiling-script">5.4 Offline Profiling Script</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#profiling-during-benchmarks">5.5 Profiling During Benchmarks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#speculative-decoding-mtp">6. Speculative Decoding (MTP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#architecture">6.1 Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#id1">6.2 Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#mtp-statistics">6.3 MTP Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#how-rejection-sampling-works">6.4 How Rejection Sampling Works</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#deployment-examples">7. Deployment Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#single-gpu">7.1 Single-GPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#multi-gpu-with-tensor-parallelism">7.2 Multi-GPU with Tensor Parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#docker-deployment">7.3 Docker Deployment</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#engine-cli-arguments-engineargs">7.4 Engine CLI Arguments (EngineArgs)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#accuracy-validation">8. Accuracy Validation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#setup">8.1 Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="serving_benchmarking_guide.html#run-evaluation">8.2 Run Evaluation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="serving_benchmarking_guide.html#source-files">Source Files</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/serving.html">Serving API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api/serving.html#llmengine-class">LLMEngine Class</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/serving.html#methods">Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api/serving.html#generate">generate()</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/serving.html#samplingparams">SamplingParams</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/serving.html#return-values">Return Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/serving.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api/models.html">Supported Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api/models.html#llama-models">Llama Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/models.html#gpt-models">GPT Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/models.html#mixtral">Mixtral</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/models.html#other-architectures">Other Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/models.html#model-configuration">Model Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/models.html#performance-by-model-size">Performance by Model Size</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/models.html#quantization">Quantization</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #C00000" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ATOM</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">ATOM Scheduling &amp; KV Cache Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/scheduling_kv_cache_guide.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="atom-scheduling-kv-cache-guide">
<h1>ATOM Scheduling &amp; KV Cache Guide<a class="headerlink" href="#atom-scheduling-kv-cache-guide" title="Link to this heading"></a></h1>
<p>ATOM (AiTer Optimized Model) uses a prefill-first scheduler with paged KV cache block management to drive LLM inference on AMD ROCm/HIP GPUs. This guide covers the scheduling algorithm, batch construction, block-level KV cache management, prefix caching, postprocessing, speculative decoding integration, and sequence lifecycle.</p>
<section id="quick-reference">
<h2>Quick Reference<a class="headerlink" href="#quick-reference" title="Link to this heading"></a></h2>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Class</p></th>
<th class="head"><p>File</p></th>
<th class="head"><p>Purpose</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Scheduler</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/scheduler.py</span></code></p></td>
<td><p>Orchestrates prefill/decode scheduling, preemption, and postprocessing</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">ScheduledBatch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/scheduler.py</span></code></p></td>
<td><p>Immutable snapshot of a scheduled batch sent to the model runner</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ScheduledBatchOutput</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/scheduler.py</span></code></p></td>
<td><p>Holds sampled token IDs and draft token IDs returned from forward pass</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">BlockManager</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/block_manager.py</span></code></p></td>
<td><p>Manages paged KV cache blocks with allocation, deallocation, and prefix caching</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Block</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/block_manager.py</span></code></p></td>
<td><p>Single KV cache block with ID, reference count, hash, and token IDs</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Sequence</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/sequence.py</span></code></p></td>
<td><p>Tracks a single request through its lifetime (tokens, blocks, status, timing)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SequenceStatus</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/sequence.py</span></code></p></td>
<td><p>Enum: <code class="docutils literal notranslate"><span class="pre">WAITING</span></code>, <code class="docutils literal notranslate"><span class="pre">RUNNING</span></code>, <code class="docutils literal notranslate"><span class="pre">FINISHED</span></code>, <code class="docutils literal notranslate"><span class="pre">EXIT_ENGINE</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SequenceType</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/sequence.py</span></code></p></td>
<td><p>Enum: <code class="docutils literal notranslate"><span class="pre">DUMMY</span></code>, <code class="docutils literal notranslate"><span class="pre">PREFILL</span></code>, <code class="docutils literal notranslate"><span class="pre">DECODE</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">RequestOutput</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/request.py</span></code></p></td>
<td><p>Dataclass streamed to clients with new tokens and finish status</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Config</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom/config.py</span></code></p></td>
<td><p>Scheduling-related fields: <code class="docutils literal notranslate"><span class="pre">max_num_seqs</span></code>, <code class="docutils literal notranslate"><span class="pre">max_num_batched_tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">kv_cache_block_size</span></code>, etc.</p></td>
</tr>
</tbody>
</table>
<p><strong>Key config defaults:</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">max_num_seqs</span></code></p></td>
<td><p>512</p></td>
<td><p>Maximum sequences in a single batch</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">max_num_batched_tokens</span></code></p></td>
<td><p>16384</p></td>
<td><p>Maximum tokens scheduled in a single step</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kv_cache_block_size</span></code></p></td>
<td><p>16</p></td>
<td><p>Tokens per KV cache block (must be multiple of 16, or 1)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">enable_prefix_caching</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">False</span></code></p></td>
<td><p>Enable hash-based prefix block sharing</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">scheduler_delay_factor</span></code></p></td>
<td><p>0.0</p></td>
<td><p>Delay factor for batching prompt requests (0 = no delay)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">gpu_memory_utilization</span></code></p></td>
<td><p>0.9</p></td>
<td><p>Fraction of GPU memory for KV cache</p></td>
</tr>
</tbody>
</table>
</section>
<hr class="docutils" />
<section id="scheduling-algorithm">
<h2>1. Scheduling Algorithm<a class="headerlink" href="#scheduling-algorithm" title="Link to this heading"></a></h2>
<p>The scheduler implements a <strong>prefill-first</strong> policy: all waiting (prefill) requests are scheduled before any running (decode) requests. The entry point is <code class="docutils literal notranslate"><span class="pre">Scheduler.schedule()</span></code>, which returns a <code class="docutils literal notranslate"><span class="pre">(ScheduledBatch,</span> <span class="pre">dict[int,</span> <span class="pre">Sequence])</span></code> tuple or <code class="docutils literal notranslate"><span class="pre">None</span></code> if both queues are empty.</p>
<section id="scheduler-initialization">
<h3>1.1 Scheduler Initialization<a class="headerlink" href="#scheduler-initialization" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Scheduler</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_num_seqs</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_num_seqs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_num_batched_tokens</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_num_batched_tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bos_token_id</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">bos_token_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_token_ids</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">stop_token_ids</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block_manager</span> <span class="o">=</span> <span class="n">BlockManager</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">waiting</span><span class="p">:</span> <span class="n">deque</span><span class="p">[</span><span class="n">Sequence</span><span class="p">]</span> <span class="o">=</span> <span class="n">deque</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running</span><span class="p">:</span> <span class="n">deque</span><span class="p">[</span><span class="n">Sequence</span><span class="p">]</span> <span class="o">=</span> <span class="n">deque</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_time</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_prompt</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_prompt_latency</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delay_factor</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">scheduler_delay_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_spec</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">speculative_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mtp_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">config</span><span class="o">.</span><span class="n">speculative_config</span><span class="o">.</span><span class="n">num_speculative_tokens</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_spec</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_draft_tokens</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_accepted_tokens</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
<p>The scheduler maintains two deques – <code class="docutils literal notranslate"><span class="pre">waiting</span></code> (pending prefill) and <code class="docutils literal notranslate"><span class="pre">running</span></code> (active decode) – plus a <code class="docutils literal notranslate"><span class="pre">BlockManager</span></code> for KV cache allocation.</p>
</section>
<section id="schedule-flow">
<h3>1.2 Schedule Flow<a class="headerlink" href="#schedule-flow" title="Link to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Scheduler.schedule()</span></code> proceeds in two phases:</p>
<p><strong>Phase 1 – Prefill scheduling:</strong></p>
<ol class="arabic simple">
<li><p>While the delay gate passes (<code class="docutils literal notranslate"><span class="pre">_passed_delay</span></code>), the waiting queue is non-empty, and <code class="docutils literal notranslate"><span class="pre">num_seqs_prefill</span> <span class="pre">&lt;</span> <span class="pre">max_num_seqs</span></code>:</p>
<ul class="simple">
<li><p>Peek the first waiting sequence.</p></li>
<li><p>Compute <code class="docutils literal notranslate"><span class="pre">num_new_tokens</span> <span class="pre">=</span> <span class="pre">seq.num_tokens</span> <span class="pre">-</span> <span class="pre">seq.num_cached_tokens</span></code> (prefix cache hits reduce new tokens).</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">num_batched_tokens</span> <span class="pre">+</span> <span class="pre">num_new_tokens</span> <span class="pre">&gt;</span> <span class="pre">max_num_batched_tokens</span></code> or <code class="docutils literal notranslate"><span class="pre">block_manager.can_allocate(seq)</span></code> returns <code class="docutils literal notranslate"><span class="pre">False</span></code>, break.</p></li>
<li><p>Otherwise: allocate blocks, set <code class="docutils literal notranslate"><span class="pre">seq.status</span> <span class="pre">=</span> <span class="pre">RUNNING</span></code>, <code class="docutils literal notranslate"><span class="pre">seq.type</span> <span class="pre">=</span> <span class="pre">PREFILL</span></code>, move from <code class="docutils literal notranslate"><span class="pre">waiting</span></code> to <code class="docutils literal notranslate"><span class="pre">running</span></code>.</p></li>
</ul>
</li>
<li><p>If any prefill sequences were scheduled, return the batch immediately (no decode mixing).</p></li>
</ol>
<p><strong>Phase 2 – Decode scheduling (only when zero prefills were scheduled):</strong></p>
<ol class="arabic simple">
<li><p>Pop sequences from <code class="docutils literal notranslate"><span class="pre">running</span></code> up to <code class="docutils literal notranslate"><span class="pre">max_num_seqs</span></code>.</p></li>
<li><p>For each sequence, check <code class="docutils literal notranslate"><span class="pre">block_manager.can_append(seq)</span></code>.</p></li>
<li><p>If a block cannot be appended, <strong>preempt</strong> the last running sequence (move it back to <code class="docutils literal notranslate"><span class="pre">waiting</span></code> with status <code class="docutils literal notranslate"><span class="pre">WAITING</span></code> and deallocate its blocks).</p></li>
<li><p>If the sequence has speculative draft tokens (<code class="docutils literal notranslate"><span class="pre">seq.spec_token_ids</span></code>), record them in <code class="docutils literal notranslate"><span class="pre">scheduled_spec_decode_tokens</span></code>.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">block_manager.may_append(seq,</span> <span class="pre">num_new_tokens)</span></code> where <code class="docutils literal notranslate"><span class="pre">num_new_tokens</span> <span class="pre">=</span> <span class="pre">mtp_k</span> <span class="pre">+</span> <span class="pre">1</span></code>.</p></li>
<li><p>Re-insert all scheduled sequences back into <code class="docutils literal notranslate"><span class="pre">running</span></code> (preserving order).</p></li>
</ol>
</section>
<section id="delay-factor">
<h3>1.3 Delay Factor<a class="headerlink" href="#delay-factor" title="Link to this heading"></a></h3>
<p>When <code class="docutils literal notranslate"><span class="pre">scheduler_delay_factor</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>, the scheduler delays prefill scheduling to allow the waiting queue to accumulate more requests for better batching:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_passed_delay</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">now</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prev_prompt</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_prompt_latency</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">prev_time</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prev_time</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prev_prompt</span> <span class="o">=</span> <span class="n">now</span><span class="p">,</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay_factor</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">waiting</span><span class="p">:</span>
        <span class="n">earliest_arrival_time</span> <span class="o">=</span> <span class="nb">min</span><span class="p">([</span><span class="n">seq</span><span class="o">.</span><span class="n">arrive_time</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">waiting</span><span class="p">])</span>
        <span class="n">passed_delay</span> <span class="o">=</span> <span class="p">(</span><span class="n">now</span> <span class="o">-</span> <span class="n">earliest_arrival_time</span><span class="p">)</span> <span class="o">&gt;</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">delay_factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_prompt_latency</span>
        <span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">running</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">passed_delay</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="n">passed_delay</span>
</pre></div>
</div>
<p>A new prefill is scheduled only when the earliest waiting request has waited longer than <code class="docutils literal notranslate"><span class="pre">delay_factor</span> <span class="pre">*</span> <span class="pre">last_prompt_latency</span></code>, or when there are no running decode requests.</p>
</section>
<section id="preemption">
<h3>1.4 Preemption<a class="headerlink" href="#preemption" title="Link to this heading"></a></h3>
<p>When a decode step cannot extend a sequence’s KV cache (no free blocks), the scheduler preempts the <strong>last</strong> running sequence:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">preempt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">):</span>
    <span class="n">seq</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">SequenceStatus</span><span class="o">.</span><span class="n">WAITING</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">block_manager</span><span class="o">.</span><span class="n">deallocate</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">waiting</span><span class="o">.</span><span class="n">appendleft</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
</pre></div>
</div>
<p>The preempted sequence is pushed to the front of the waiting queue and its blocks are fully deallocated, so it will be re-prefilled on the next scheduling cycle.</p>
</section>
</section>
<hr class="docutils" />
<section id="scheduledbatch-structure">
<h2>2. ScheduledBatch Structure<a class="headerlink" href="#scheduledbatch-structure" title="Link to this heading"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">ScheduledBatch</span></code> is constructed by <code class="docutils literal notranslate"><span class="pre">Scheduler.schedule()</span></code> and passed to the model runner. It is a frozen snapshot of batch metadata.</p>
<section id="constructor-signature">
<h3>2.1 Constructor Signature<a class="headerlink" href="#constructor-signature" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ScheduledBatch</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">seqs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">],</span>
        <span class="n">num_scheduled_tokens</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">total_tokens_num</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">total_tokens_num_prefill</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">total_tokens_num_decode</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">total_seqs_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">total_seqs_num_prefill</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">total_seqs_num_decode</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">is_dummy_run</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_spec_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">scheduled_spec_decode_tokens</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="p">):</span>
</pre></div>
</div>
</section>
<section id="fields">
<h3>2.2 Fields<a class="headerlink" href="#fields" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">req_ids</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Sequence IDs in batch order (<code class="docutils literal notranslate"><span class="pre">list(seqs.keys())</span></code>)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">scheduled_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[list[int]]</span></code></p></td>
<td><p>Last <code class="docutils literal notranslate"><span class="pre">num_tokens</span></code> token IDs per sequence (the tokens to process)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">temperatures</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[float]</span></code></p></td>
<td><p>Sampling temperature per sequence</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">context_lens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Total token count per sequence (<code class="docutils literal notranslate"><span class="pre">seq.num_tokens</span></code>)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">block_tables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[list[int]]</span></code></p></td>
<td><p>Block ID tables for sequences that have block tables</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">last_block_num_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Number of valid tokens in each sequence’s last block</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">num_cached_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Number of tokens served from prefix cache per sequence</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">num_scheduled_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Number of new tokens scheduled per sequence</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">total_tokens_num</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Sum of all scheduled tokens across all sequences</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">total_tokens_num_prefill</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Total scheduled tokens for prefill sequences</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">total_tokens_num_decode</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Total scheduled tokens for decode sequences</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">total_seqs_num</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Total number of sequences in the batch</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">total_seqs_num_prefill</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Number of prefill sequences</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">total_seqs_num_decode</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Number of decode sequences</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">is_dummy_run</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bool</span></code></p></td>
<td><p>Whether this is a dummy/warmup run</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">num_spec_step</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Number of speculative decode steps (<code class="docutils literal notranslate"><span class="pre">mtp_k</span></code>)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">scheduled_spec_decode_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">dict[int,</span> <span class="pre">list[int]]</span></code></p></td>
<td><p>Draft token IDs per sequence ID from prior speculative step</p></td>
</tr>
</tbody>
</table>
</section>
<section id="scheduledbatchoutput">
<h3>2.3 ScheduledBatchOutput<a class="headerlink" href="#scheduledbatchoutput" title="Link to this heading"></a></h3>
<p>Returned by the model runner after a forward pass:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ScheduledBatchOutput</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">token_ids</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span>
        <span class="n">draft_token_ids</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">req_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">token_ids</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_ids</span> <span class="o">=</span> <span class="n">token_ids</span>        <span class="c1"># {seq_id: (accepted_token_ids...)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">draft_token_ids</span> <span class="o">=</span> <span class="n">draft_token_ids</span>  <span class="c1"># {seq_id: [draft_ids]} or None</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">token_ids</span></code> maps sequence ID to a tuple of accepted token IDs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">draft_token_ids</span></code> maps sequence ID to a list of speculative draft token IDs for the next step (when MTP is active).</p></li>
<li><p>A special key <code class="docutils literal notranslate"><span class="pre">-1</span></code> in <code class="docutils literal notranslate"><span class="pre">token_ids</span></code> signals deferred output mode.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="block-manager">
<h2>3. Block Manager<a class="headerlink" href="#block-manager" title="Link to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">BlockManager</span></code> implements paged KV cache management with fixed-size blocks.</p>
<section id="block-class">
<h3>3.1 Block Class<a class="headerlink" href="#block-class" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Block</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_id</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block_id</span> <span class="o">=</span> <span class="n">block_id</span>   <span class="c1"># Unique integer ID</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_count</span> <span class="o">=</span> <span class="mi">0</span>         <span class="c1"># Number of sequences referencing this block</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hash</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>             <span class="c1"># xxhash64 digest for prefix caching (-1 = unhashed)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_ids</span> <span class="o">=</span> <span class="p">[]</span>        <span class="c1"># Token IDs stored in this block</span>
</pre></div>
</div>
<p>Methods:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">update(hash,</span> <span class="pre">token_ids)</span></code> – Sets the block’s hash and token content.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reset()</span></code> – Sets <code class="docutils literal notranslate"><span class="pre">ref_count</span> <span class="pre">=</span> <span class="pre">1</span></code>, <code class="docutils literal notranslate"><span class="pre">hash</span> <span class="pre">=</span> <span class="pre">-1</span></code>, <code class="docutils literal notranslate"><span class="pre">token_ids</span> <span class="pre">=</span> <span class="pre">[]</span></code> (used on fresh allocation).</p></li>
</ul>
</section>
<section id="blockmanager-initialization">
<h3>3.2 BlockManager Initialization<a class="headerlink" href="#blockmanager-initialization" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BlockManager</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">):</span>
        <span class="n">block_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">kv_cache_block_size</span>      <span class="c1"># Tokens per block (default 16)</span>
        <span class="n">num_blocks</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_kvcache_blocks</span>        <span class="c1"># Total blocks in pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">block_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Block</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Block</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hash_to_block_id</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">free_block_ids</span><span class="p">:</span> <span class="n">deque</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">used_block_ids</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enable_prefix_caching</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">enable_prefix_caching</span>
</pre></div>
</div>
<p>The block pool is pre-allocated at startup. <code class="docutils literal notranslate"><span class="pre">free_block_ids</span></code> is a deque for O(1) pop/push, <code class="docutils literal notranslate"><span class="pre">used_block_ids</span></code> tracks active blocks, and <code class="docutils literal notranslate"><span class="pre">hash_to_block_id</span></code> maps content hashes to block IDs for prefix caching.</p>
</section>
<section id="allocation-allocate">
<h3>3.3 Allocation (<code class="docutils literal notranslate"><span class="pre">allocate</span></code>)<a class="headerlink" href="#allocation-allocate" title="Link to this heading"></a></h3>
<p>Called during prefill scheduling for new sequences:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">allocate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">):</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p>Iterates over <code class="docutils literal notranslate"><span class="pre">seq.num_blocks</span></code> blocks.</p></li>
<li><p>For each block, computes hash if the block is full (<code class="docutils literal notranslate"><span class="pre">len(token_ids)</span> <span class="pre">==</span> <span class="pre">block_size</span></code>). Partial (last) blocks get <code class="docutils literal notranslate"><span class="pre">hash</span> <span class="pre">=</span> <span class="pre">-1</span></code>.</p></li>
<li><p>If prefix caching is enabled, looks up <code class="docutils literal notranslate"><span class="pre">hash_to_block_id</span></code>:</p>
<ul class="simple">
<li><p><strong>Cache hit:</strong> Verifies <code class="docutils literal notranslate"><span class="pre">token_ids</span></code> match. If the block is already in <code class="docutils literal notranslate"><span class="pre">used_block_ids</span></code>, increments <code class="docutils literal notranslate"><span class="pre">ref_count</span></code>. If it was evicted but still in the free list, re-allocates it. Increments <code class="docutils literal notranslate"><span class="pre">seq.num_cached_tokens</span></code> by <code class="docutils literal notranslate"><span class="pre">block_size</span></code>.</p></li>
<li><p><strong>Cache miss:</strong> Allocates from <code class="docutils literal notranslate"><span class="pre">free_block_ids[0]</span></code>.</p></li>
</ul>
</li>
<li><p>Full blocks are registered in <code class="docutils literal notranslate"><span class="pre">hash_to_block_id</span></code>.</p></li>
</ol>
</section>
<section id="deallocation-deallocate">
<h3>3.4 Deallocation (<code class="docutils literal notranslate"><span class="pre">deallocate</span></code>)<a class="headerlink" href="#deallocation-deallocate" title="Link to this heading"></a></h3>
<p>Called when a sequence finishes or is preempted:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">deallocate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">block_id</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">seq</span><span class="o">.</span><span class="n">block_table</span><span class="p">):</span>
        <span class="n">block</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">[</span><span class="n">block_id</span><span class="p">]</span>
        <span class="n">block</span><span class="o">.</span><span class="n">ref_count</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">block</span><span class="o">.</span><span class="n">ref_count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_deallocate_block</span><span class="p">(</span><span class="n">block_id</span><span class="p">)</span>
    <span class="n">seq</span><span class="o">.</span><span class="n">num_cached_tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">seq</span><span class="o">.</span><span class="n">block_table</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
<p>Blocks are released in reverse order. Shared blocks (with <code class="docutils literal notranslate"><span class="pre">ref_count</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> from prefix caching) are not freed until all referencing sequences release them.</p>
</section>
<section id="can-allocate-and-can-append-checks">
<h3>3.5 Can-Allocate and Can-Append Checks<a class="headerlink" href="#can-allocate-and-can-append-checks" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">can_allocate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">free_block_ids</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">seq</span><span class="o">.</span><span class="n">num_blocks</span>

<span class="k">def</span><span class="w"> </span><span class="nf">can_append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">free_block_ids</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">can_allocate</span></code> checks that enough free blocks exist for the full sequence.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">can_append</span></code> checks whether a decode step needs a new block. A new block is needed only when <code class="docutils literal notranslate"><span class="pre">len(seq)</span> <span class="pre">%</span> <span class="pre">block_size</span> <span class="pre">==</span> <span class="pre">1</span></code> (the previous block just filled up), requiring exactly 1 free block.</p></li>
</ul>
</section>
<section id="may-append-decode-extension">
<h3>3.6 May-Append (Decode Extension)<a class="headerlink" href="#may-append-decode-extension" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">may_append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">num_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
</pre></div>
</div>
<p>Called during decode scheduling to extend a sequence’s block table:</p>
<ol class="arabic simple">
<li><p>If the sequence length modulo <code class="docutils literal notranslate"><span class="pre">block_size</span></code> falls within <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">num_new_tokens]</span></code>, or <code class="docutils literal notranslate"><span class="pre">block_size</span> <span class="pre">==</span> <span class="pre">1</span></code>, a new block is needed:</p>
<ul class="simple">
<li><p>Allocates from <code class="docutils literal notranslate"><span class="pre">free_block_ids</span></code> and appends to <code class="docutils literal notranslate"><span class="pre">block_table</span></code>.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">block_size</span> <span class="pre">==</span> <span class="pre">1</span></code>, immediately computes and stores the hash.</p></li>
</ul>
</li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">seq_len</span> <span class="pre">%</span> <span class="pre">block_size</span> <span class="pre">==</span> <span class="pre">0</span></code>, the last block is now full – computes and stores its hash using the chained prefix.</p></li>
<li><p>Otherwise the last block is partially filled with <code class="docutils literal notranslate"><span class="pre">hash</span> <span class="pre">=</span> <span class="pre">-1</span></code> (hash deferred until full).</p></li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="prefix-caching">
<h2>4. Prefix Caching<a class="headerlink" href="#prefix-caching" title="Link to this heading"></a></h2>
<p>Prefix caching enables sharing KV cache blocks across sequences that share a common prompt prefix, avoiding redundant computation.</p>
<section id="hash-function">
<h3>4.1 Hash Function<a class="headerlink" href="#hash-function" title="Link to this heading"></a></h3>
<p>ATOM uses <code class="docutils literal notranslate"><span class="pre">xxhash64</span></code> (via the <code class="docutils literal notranslate"><span class="pre">xxhash</span></code> Python library) for fast, collision-resistant block hashing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_hash</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">xxhash</span><span class="o">.</span><span class="n">xxh64</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">prefix</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">h</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">prefix</span><span class="o">.</span><span class="n">to_bytes</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;little&quot;</span><span class="p">))</span>
    <span class="n">h</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span><span class="o">.</span><span class="n">tobytes</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">h</span><span class="o">.</span><span class="n">intdigest</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="hash-chaining">
<h3>4.2 Hash Chaining<a class="headerlink" href="#hash-chaining" title="Link to this heading"></a></h3>
<p>Blocks form a hash chain: each block’s hash incorporates the previous block’s hash as a prefix. This ensures that two blocks with identical token content but different preceding context produce different hashes.</p>
<ul class="simple">
<li><p>First block: <code class="docutils literal notranslate"><span class="pre">compute_hash(token_ids,</span> <span class="pre">prefix=-1)</span></code> (no prefix).</p></li>
<li><p>Subsequent blocks: <code class="docutils literal notranslate"><span class="pre">compute_hash(token_ids,</span> <span class="pre">prefix=prev_block.hash)</span></code>.</p></li>
<li><p>Only <strong>full</strong> blocks (where <code class="docutils literal notranslate"><span class="pre">len(token_ids)</span> <span class="pre">==</span> <span class="pre">block_size</span></code>) receive a hash. Partial blocks have <code class="docutils literal notranslate"><span class="pre">hash</span> <span class="pre">=</span> <span class="pre">-1</span></code> and are not cached.</p></li>
</ul>
</section>
<section id="cache-lookup-during-allocation">
<h3>4.3 Cache Lookup During Allocation<a class="headerlink" href="#cache-lookup-during-allocation" title="Link to this heading"></a></h3>
<p>During <code class="docutils literal notranslate"><span class="pre">allocate()</span></code>, for each full block:</p>
<ol class="arabic simple">
<li><p>Compute the block hash via the chain.</p></li>
<li><p>Look up <code class="docutils literal notranslate"><span class="pre">hash_to_block_id.get(h,</span> <span class="pre">-1)</span></code>.</p></li>
<li><p>If found, verify <code class="docutils literal notranslate"><span class="pre">self.blocks[block_id].token_ids</span> <span class="pre">==</span> <span class="pre">token_ids</span></code> (guard against hash collisions).</p></li>
<li><p><strong>Hit:</strong> Reuse the block. If already in <code class="docutils literal notranslate"><span class="pre">used_block_ids</span></code>, increment <code class="docutils literal notranslate"><span class="pre">ref_count</span></code>. Add <code class="docutils literal notranslate"><span class="pre">block_size</span></code> to <code class="docutils literal notranslate"><span class="pre">seq.num_cached_tokens</span></code>.</p></li>
<li><p><strong>Miss (or first miss in chain):</strong> Once a cache miss occurs, all subsequent blocks in the sequence are also misses (<code class="docutils literal notranslate"><span class="pre">cache_miss</span> <span class="pre">=</span> <span class="pre">True</span></code> is sticky). Allocate fresh blocks from the free list.</p></li>
</ol>
</section>
<section id="reference-counting">
<h3>4.4 Reference Counting<a class="headerlink" href="#reference-counting" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>On allocation: <code class="docutils literal notranslate"><span class="pre">block.reset()</span></code> sets <code class="docutils literal notranslate"><span class="pre">ref_count</span> <span class="pre">=</span> <span class="pre">1</span></code>.</p></li>
<li><p>On cache hit for an in-use block: <code class="docutils literal notranslate"><span class="pre">ref_count</span> <span class="pre">+=</span> <span class="pre">1</span></code>.</p></li>
<li><p>On deallocation: <code class="docutils literal notranslate"><span class="pre">ref_count</span> <span class="pre">-=</span> <span class="pre">1</span></code>. Block returns to free list only when <code class="docutils literal notranslate"><span class="pre">ref_count</span> <span class="pre">==</span> <span class="pre">0</span></code>.</p></li>
<li><p>Shared blocks (prefix cache hits) have <code class="docutils literal notranslate"><span class="pre">ref_count</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>.</p></li>
</ul>
</section>
<section id="enabling-prefix-caching">
<h3>4.5 Enabling Prefix Caching<a class="headerlink" href="#enabling-prefix-caching" title="Link to this heading"></a></h3>
<p>Set <code class="docutils literal notranslate"><span class="pre">enable_prefix_caching=True</span></code> in <code class="docutils literal notranslate"><span class="pre">Config</span></code>. When disabled, the hash lookup in <code class="docutils literal notranslate"><span class="pre">allocate()</span></code> is skipped entirely (<code class="docutils literal notranslate"><span class="pre">block_id</span></code> is always <code class="docutils literal notranslate"><span class="pre">-1</span></code>).</p>
</section>
</section>
<hr class="docutils" />
<section id="postprocessing">
<h2>5. Postprocessing<a class="headerlink" href="#postprocessing" title="Link to this heading"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Scheduler.postprocess()</span></code> is called after the model forward pass to update sequences with sampled tokens, check stop conditions, generate streaming output, and clean up finished sequences.</p>
<section id="signature">
<h3>5.1 Signature<a class="headerlink" href="#signature" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">postprocess</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">seqs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Sequence</span><span class="p">],</span>
    <span class="n">fwd_output</span><span class="p">:</span> <span class="n">ScheduledBatchOutput</span><span class="p">,</span>
    <span class="n">stream_output_queue</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Sequence</span><span class="p">]:</span>
</pre></div>
</div>
</section>
<section id="token-appending">
<h3>5.2 Token Appending<a class="headerlink" href="#token-appending" title="Link to this heading"></a></h3>
<p>For each running sequence whose ID appears in <code class="docutils literal notranslate"><span class="pre">fwd_output.req_ids</span></code>:</p>
<ul>
<li><p><strong>Deferred output or speculative decode with EOS:</strong> Replaces placeholder tokens in-place:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">seq</span><span class="o">.</span><span class="n">token_ids</span><span class="p">[</span><span class="o">-</span><span class="n">num_placeholder</span><span class="p">:]</span> <span class="o">=</span> <span class="n">token_ids</span>
<span class="n">seq</span><span class="o">.</span><span class="n">output_tokens</span><span class="p">[</span><span class="o">-</span><span class="n">num_placeholder</span><span class="p">:]</span> <span class="o">=</span> <span class="n">token_ids</span>
</pre></div>
</div>
</li>
<li><p><strong>Normal path:</strong> Calls <code class="docutils literal notranslate"><span class="pre">seq.append_token(token_id)</span></code> for each accepted token, which appends to <code class="docutils literal notranslate"><span class="pre">token_ids</span></code>, updates <code class="docutils literal notranslate"><span class="pre">output_tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">last_token</span></code>, and <code class="docutils literal notranslate"><span class="pre">num_tokens</span></code>.</p></li>
</ul>
</section>
<section id="stop-condition-checking">
<h3>5.3 Stop Condition Checking<a class="headerlink" href="#stop-condition-checking" title="Link to this heading"></a></h3>
<p>The postprocessor checks stop conditions in priority order:</p>
<ol class="arabic simple">
<li><p><strong>Stop token sequences:</strong> Compares the tail of <code class="docutils literal notranslate"><span class="pre">seq.token_ids</span></code> against each entry in <code class="docutils literal notranslate"><span class="pre">seq.stop_token_sequences</span></code>. Also checks the MTP-adjusted position for speculative decode. Sets <code class="docutils literal notranslate"><span class="pre">leave_reason</span> <span class="pre">=</span> <span class="pre">&quot;stop_sequence&quot;</span></code>.</p></li>
<li><p><strong>EOS token:</strong> If <code class="docutils literal notranslate"><span class="pre">self.eos_token_id</span></code> appears in the accepted tokens and <code class="docutils literal notranslate"><span class="pre">seq.ignore_eos</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Sets <code class="docutils literal notranslate"><span class="pre">leave_reason</span> <span class="pre">=</span> <span class="pre">&quot;eos&quot;</span></code>.</p></li>
<li><p><strong>Stop token IDs:</strong> If any accepted token is in <code class="docutils literal notranslate"><span class="pre">self.stop_token_ids</span></code> (from <code class="docutils literal notranslate"><span class="pre">Config.stop_token_ids</span></code>, derived from the model’s generation config). Sets <code class="docutils literal notranslate"><span class="pre">leave_reason</span> <span class="pre">=</span> <span class="pre">&quot;stop_{token_id}&quot;</span></code>.</p></li>
<li><p><strong>Max tokens:</strong> If <code class="docutils literal notranslate"><span class="pre">seq.num_completion_tokens</span> <span class="pre">&gt;=</span> <span class="pre">seq.max_tokens</span></code>. Sets <code class="docutils literal notranslate"><span class="pre">leave_reason</span> <span class="pre">=</span> <span class="pre">&quot;max_tokens&quot;</span></code>.</p></li>
</ol>
</section>
<section id="stream-output">
<h3>5.4 Stream Output<a class="headerlink" href="#stream-output" title="Link to this heading"></a></h3>
<p>When <code class="docutils literal notranslate"><span class="pre">stream_output_queue</span></code> is provided, the scheduler creates a <code class="docutils literal notranslate"><span class="pre">RequestOutput</span></code> for each processed sequence:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">request_output</span> <span class="o">=</span> <span class="n">RequestOutput</span><span class="p">(</span>
    <span class="n">request_id</span><span class="o">=</span><span class="n">seq</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
    <span class="n">output_tokens</span><span class="o">=</span><span class="n">output_tokens_list</span><span class="p">,</span>
    <span class="n">finished</span><span class="o">=</span><span class="p">(</span><span class="n">leave_reason</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">),</span>
    <span class="n">finish_reason</span><span class="o">=</span><span class="n">leave_reason</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">RequestOutput</span></code> fields:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">request_id</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Sequence ID</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">output_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Newly generated tokens since last callback</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">finished</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bool</span></code></p></td>
<td><p>Whether the sequence is done</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">finish_reason</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Optional[str]</span></code></p></td>
<td><p>One of: <code class="docutils literal notranslate"><span class="pre">&quot;eos&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;max_tokens&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;stop_sequence&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;stop_{token_id}&quot;</span></code>, or <code class="docutils literal notranslate"><span class="pre">None</span></code></p></td>
</tr>
</tbody>
</table>
<p>Stream outputs are batched and put onto <code class="docutils literal notranslate"><span class="pre">stream_output_queue</span></code> via <code class="docutils literal notranslate"><span class="pre">put_nowait</span></code>.</p>
</section>
<section id="sequence-cleanup">
<h3>5.5 Sequence Cleanup<a class="headerlink" href="#sequence-cleanup" title="Link to this heading"></a></h3>
<p>For finished sequences:</p>
<ol class="arabic simple">
<li><p>Set <code class="docutils literal notranslate"><span class="pre">seq.status</span> <span class="pre">=</span> <span class="pre">SequenceStatus.FINISHED</span></code>.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">block_manager.deallocate(seq)</span></code> to free KV cache blocks.</p></li>
<li><p>Remove from the <code class="docutils literal notranslate"><span class="pre">running</span></code> deque.</p></li>
<li><p>Return in the <code class="docutils literal notranslate"><span class="pre">finished_seqs</span></code> list.</p></li>
</ol>
</section>
<section id="placeholder-insertion">
<h3>5.6 Placeholder Insertion<a class="headerlink" href="#placeholder-insertion" title="Link to this heading"></a></h3>
<p>When speculative decoding or deferred output is active, placeholder EOS tokens are appended to still-running sequences to reserve KV cache slots for the next step:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">need_placeholder</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">seqs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">seq</span><span class="o">.</span><span class="n">status</span> <span class="o">==</span> <span class="n">SequenceStatus</span><span class="o">.</span><span class="n">RUNNING</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">seq</span><span class="o">.</span><span class="n">num_placeholder</span><span class="p">):</span>
                <span class="n">seq</span><span class="o">.</span><span class="n">append_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">)</span>
</pre></div>
</div>
<p>The placeholder count is determined as follows:</p>
<ul class="simple">
<li><p><strong>For sequences processed in this step</strong> (had output in <code class="docutils literal notranslate"><span class="pre">fwd_output</span></code>): always <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">+</span> <span class="pre">mtp_k</span></code>, regardless of mode.</p></li>
<li><p><strong>For sequences not processed</strong> (skipped in this step): the count depends on the batch-level mode:</p>
<ul>
<li><p>Deferred output + speculative: <code class="docutils literal notranslate"><span class="pre">mtp_k</span> <span class="pre">+</span> <span class="pre">1</span></code></p></li>
<li><p>Deferred output only: <code class="docutils literal notranslate"><span class="pre">1</span></code></p></li>
<li><p>Speculative only: <code class="docutils literal notranslate"><span class="pre">mtp_k</span></code></p></li>
</ul>
</li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="speculative-decoding-integration">
<h2>6. Speculative Decoding Integration<a class="headerlink" href="#speculative-decoding-integration" title="Link to this heading"></a></h2>
<p>ATOM supports Multi-Token Prediction (MTP) speculative decoding, where a draft model proposes <code class="docutils literal notranslate"><span class="pre">mtp_k</span></code> additional tokens per step.</p>
<section id="scheduler-tracking">
<h3>6.1 Scheduler Tracking<a class="headerlink" href="#scheduler-tracking" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">use_spec</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">speculative_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="bp">self</span><span class="o">.</span><span class="n">mtp_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">speculative_config</span><span class="o">.</span><span class="n">num_speculative_tokens</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_spec</span> <span class="k">else</span> <span class="mi">0</span>
<span class="bp">self</span><span class="o">.</span><span class="n">total_draft_tokens</span> <span class="o">=</span> <span class="mi">0</span>
<span class="bp">self</span><span class="o">.</span><span class="n">total_accepted_tokens</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
<p>Note: <code class="docutils literal notranslate"><span class="pre">SpeculativeConfig</span></code> currently enforces <code class="docutils literal notranslate"><span class="pre">num_speculative_tokens</span> <span class="pre">==</span> <span class="pre">1</span></code>.</p>
</section>
<section id="draft-tokens-in-scheduling">
<h3>6.2 Draft Tokens in Scheduling<a class="headerlink" href="#draft-tokens-in-scheduling" title="Link to this heading"></a></h3>
<p>During decode scheduling:</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">seq.spec_token_ids</span></code> is non-empty, the draft tokens are recorded in <code class="docutils literal notranslate"><span class="pre">scheduled_spec_decode_tokens[seq.id]</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_new_tokens</span> <span class="pre">=</span> <span class="pre">mtp_k</span> <span class="pre">+</span> <span class="pre">1</span></code> (1 target + <code class="docutils literal notranslate"><span class="pre">mtp_k</span></code> draft tokens), so <code class="docutils literal notranslate"><span class="pre">may_append</span></code> reserves enough block space.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">ScheduledBatch</span></code> carries <code class="docutils literal notranslate"><span class="pre">num_spec_step</span> <span class="pre">=</span> <span class="pre">mtp_k</span></code> and the <code class="docutils literal notranslate"><span class="pre">scheduled_spec_decode_tokens</span></code> dict.</p></li>
</ul>
</section>
<section id="acceptance-statistics">
<h3>6.3 Acceptance Statistics<a class="headerlink" href="#acceptance-statistics" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update_spec_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_accepted_tokens</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_draft_tokens</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mtp_k</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_accepted_tokens</span> <span class="o">+=</span> <span class="n">num_accepted_tokens</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mtp_k</span>
</pre></div>
</div>
<p>Every 1000 draft tokens, the acceptance rate is logged:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">MTP</span> <span class="n">Stats</span><span class="p">]</span> <span class="n">Total</span> <span class="n">draft</span> <span class="n">tokens</span><span class="p">:</span> <span class="mi">5000</span><span class="p">,</span> <span class="n">Accepted</span><span class="p">:</span> <span class="mi">3750</span><span class="p">,</span> <span class="n">Acceptance</span> <span class="n">rate</span><span class="p">:</span> <span class="mf">75.00</span><span class="o">%</span>
</pre></div>
</div>
</section>
<section id="draft-token-storage-on-sequences">
<h3>6.4 Draft Token Storage on Sequences<a class="headerlink" href="#draft-token-storage-on-sequences" title="Link to this heading"></a></h3>
<p>After postprocessing, accepted draft token IDs for the next step are stored on the sequence:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">draft_token_ids</span> <span class="ow">and</span> <span class="n">seq</span><span class="o">.</span><span class="n">id</span> <span class="ow">in</span> <span class="n">draft_token_ids</span><span class="p">:</span>
    <span class="n">seq</span><span class="o">.</span><span class="n">spec_token_ids</span> <span class="o">=</span> <span class="n">draft_token_ids</span><span class="p">[</span><span class="n">seq</span><span class="o">.</span><span class="n">id</span><span class="p">]</span>
</pre></div>
</div>
<p>These are picked up by the scheduler on the next <code class="docutils literal notranslate"><span class="pre">schedule()</span></code> call.</p>
</section>
</section>
<hr class="docutils" />
<section id="sequence-management">
<h2>7. Sequence Management<a class="headerlink" href="#sequence-management" title="Link to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">Sequence</span></code> class represents a single request throughout its lifecycle.</p>
<section id="constructor">
<h3>7.1 Constructor<a class="headerlink" href="#constructor" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Sequence</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">token_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">block_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sampling_params</span><span class="o">=</span><span class="n">SamplingParams</span><span class="p">(),</span>
        <span class="n">stop_token_sequences</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stream_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="nb">id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
</pre></div>
</div>
</section>
<section id="core-fields">
<h3>7.2 Core Fields<a class="headerlink" href="#core-fields" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">id</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Auto-incrementing unique ID (from <code class="docutils literal notranslate"><span class="pre">itertools.count</span></code>)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">token_ids</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Full token sequence (prompt + completion)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">block_size</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>KV cache block size (from config)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">status</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SequenceStatus</span></code></p></td>
<td><p>Current lifecycle state</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SequenceType</span></code></p></td>
<td><p>Current step type (<code class="docutils literal notranslate"><span class="pre">DUMMY</span></code>, <code class="docutils literal notranslate"><span class="pre">PREFILL</span></code>, <code class="docutils literal notranslate"><span class="pre">DECODE</span></code>)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">num_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Total tokens (prompt + completion); property with setter that also updates <code class="docutils literal notranslate"><span class="pre">num_blocks</span></code> and <code class="docutils literal notranslate"><span class="pre">last_block_num_tokens</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">num_prompt_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Number of prompt tokens (fixed at init)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">num_cached_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Tokens served from prefix cache</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">block_table</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Ordered list of block IDs assigned to this sequence</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">last_token</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Most recently appended token ID</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">temperature</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">float</span></code></p></td>
<td><p>Sampling temperature (from <code class="docutils literal notranslate"><span class="pre">SamplingParams</span></code>)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">max_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Max completion tokens (from <code class="docutils literal notranslate"><span class="pre">SamplingParams</span></code>, default 64)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ignore_eos</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bool</span></code></p></td>
<td><p>Whether to ignore EOS tokens (from <code class="docutils literal notranslate"><span class="pre">SamplingParams</span></code>)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">stop_strings</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Optional[list[str]]</span></code></p></td>
<td><p>Stop strings (from <code class="docutils literal notranslate"><span class="pre">SamplingParams</span></code>)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">stop_token_sequences</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[list[int]]</span></code></p></td>
<td><p>Token-level stop sequences</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">stream_callback</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Optional[Callable]</span></code></p></td>
<td><p>Per-sequence stream callback</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">output_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Cache of newly generated tokens</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">spec_token_ids</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">list[int]</span></code></p></td>
<td><p>Speculative draft token IDs for next step</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">num_placeholder</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Number of placeholder tokens inserted for speculative/deferred output</p></td>
</tr>
</tbody>
</table>
</section>
<section id="timing-fields">
<h3>7.3 Timing Fields<a class="headerlink" href="#timing-fields" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">arrive_time</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">float</span></code></p></td>
<td><p>Timestamp when the sequence entered the scheduler</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">first_token_time</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">float</span></code></p></td>
<td><p>Timestamp of the first completion token (TTFT measurement)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">leave_time</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">float</span></code></p></td>
<td><p>Timestamp when the sequence finished</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">leave_reason</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">str</span></code></p></td>
<td><p>Reason for finishing (e.g., <code class="docutils literal notranslate"><span class="pre">&quot;eos&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;max_tokens&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;stop_sequence&quot;</span></code>)</p></td>
</tr>
</tbody>
</table>
</section>
<section id="computed-properties">
<h3>7.4 Computed Properties<a class="headerlink" href="#computed-properties" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Returns</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">num_completion_tokens</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">num_tokens</span> <span class="pre">-</span> <span class="pre">num_prompt_tokens</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">prompt_token_ids</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">token_ids[:num_prompt_tokens]</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">completion_token_ids</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">token_ids[num_prompt_tokens:]</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">num_cached_blocks</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">num_cached_tokens</span> <span class="pre">//</span> <span class="pre">block_size</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">is_finished</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">status</span> <span class="pre">==</span> <span class="pre">SequenceStatus.FINISHED</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="num-tokens-setter">
<h3>7.5 num_tokens Setter<a class="headerlink" href="#num-tokens-setter" title="Link to this heading"></a></h3>
<p>Setting <code class="docutils literal notranslate"><span class="pre">num_tokens</span></code> triggers derived field updates:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@num_tokens</span><span class="o">.</span><span class="n">setter</span>
<span class="k">def</span><span class="w"> </span><span class="nf">num_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_tokens</span> <span class="o">=</span> <span class="n">value</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">value</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">last_block_num_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_tokens</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_blocks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>
</pre></div>
</div>
</section>
<section id="lifecycle">
<h3>7.6 Lifecycle<a class="headerlink" href="#lifecycle" title="Link to this heading"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                          <span class="n">allocate</span> <span class="n">blocks</span>
   <span class="n">add</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="o">---------&gt;</span> <span class="n">WAITING</span> <span class="o">---------&gt;</span> <span class="n">RUNNING</span> <span class="p">(</span><span class="n">PREFILL</span><span class="p">)</span>
                          <span class="o">^</span>                    <span class="o">|</span>
                          <span class="o">|</span>                    <span class="o">|</span> <span class="nb">next</span> <span class="n">schedule</span><span class="p">()</span> <span class="n">step</span>
                     <span class="n">preempt</span><span class="p">()</span>                 <span class="n">v</span>
                          <span class="o">|</span>              <span class="n">RUNNING</span> <span class="p">(</span><span class="n">DECODE</span><span class="p">)</span> <span class="o">&lt;--+</span>
                          <span class="o">+---</span> <span class="n">can</span><span class="s1">&#39;t append    |             |</span>
                                               <span class="o">|</span> <span class="n">stop</span> <span class="n">condition</span> <span class="n">met</span>
                                               <span class="n">v</span>
                                           <span class="n">FINISHED</span>
                                               <span class="o">|</span>
                                               <span class="o">|</span> <span class="n">deallocate</span> <span class="n">blocks</span>
                                               <span class="n">v</span>
                                         <span class="p">(</span><span class="n">removed</span> <span class="kn">from</span><span class="w"> </span><span class="nn">running</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="sequencestatus-enum">
<h3>7.7 SequenceStatus Enum<a class="headerlink" href="#sequencestatus-enum" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Value</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">WAITING</span></code></p></td>
<td><p>In the waiting queue, pending prefill</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">RUNNING</span></code></p></td>
<td><p>Actively being processed (prefill or decode)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">FINISHED</span></code></p></td>
<td><p>Stop condition met, blocks deallocated</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">EXIT_ENGINE</span></code></p></td>
<td><p>Sentinel for engine shutdown</p></td>
</tr>
</tbody>
</table>
</section>
<section id="sequencetype-enum">
<h3>7.8 SequenceType Enum<a class="headerlink" href="#sequencetype-enum" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Value</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DUMMY</span></code></p></td>
<td><p>Initial state before scheduling</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">PREFILL</span></code></p></td>
<td><p>Currently in prefill phase</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DECODE</span></code></p></td>
<td><p>Currently in decode phase</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<hr class="docutils" />
<section id="source-files">
<h2>Source Files<a class="headerlink" href="#source-files" title="Link to this heading"></a></h2>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>File</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/scheduler.py</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Scheduler</span></code>, <code class="docutils literal notranslate"><span class="pre">ScheduledBatch</span></code>, <code class="docutils literal notranslate"><span class="pre">ScheduledBatchOutput</span></code> – scheduling algorithm, postprocessing, speculative decode stats</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/block_manager.py</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Block</span></code>, <code class="docutils literal notranslate"><span class="pre">BlockManager</span></code> – paged KV cache block pool, allocation/deallocation, prefix caching with xxhash64</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/sequence.py</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Sequence</span></code>, <code class="docutils literal notranslate"><span class="pre">SequenceStatus</span></code>, <code class="docutils literal notranslate"><span class="pre">SequenceType</span></code> – request lifecycle, token management, timing</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">atom/model_engine/request.py</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">RequestOutput</span></code> – streaming output dataclass with <code class="docutils literal notranslate"><span class="pre">request_id</span></code>, <code class="docutils literal notranslate"><span class="pre">output_tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">finished</span></code>, <code class="docutils literal notranslate"><span class="pre">finish_reason</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">atom/config.py</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Config</span></code> – scheduling-related fields (<code class="docutils literal notranslate"><span class="pre">max_num_seqs</span></code>, <code class="docutils literal notranslate"><span class="pre">max_num_batched_tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">kv_cache_block_size</span></code>, <code class="docutils literal notranslate"><span class="pre">enable_prefix_caching</span></code>, <code class="docutils literal notranslate"><span class="pre">scheduler_delay_factor</span></code>), <code class="docutils literal notranslate"><span class="pre">SpeculativeConfig</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">atom/sampling_params.py</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SamplingParams</span></code> – <code class="docutils literal notranslate"><span class="pre">temperature</span></code>, <code class="docutils literal notranslate"><span class="pre">max_tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">ignore_eos</span></code>, <code class="docutils literal notranslate"><span class="pre">stop_strings</span></code></p></td>
</tr>
</tbody>
</table>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model_ops_guide.html" class="btn btn-neutral float-left" title="ATOM Model Operations Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="distributed_guide.html" class="btn btn-neutral float-right" title="ATOM Distributed Inference Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2026, AMD.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>